# D√©tection de fraude des r√©clamations en assurance automobile

## üìå Aper√ßu du projet

La fraude en assurance automobile repr√©sente un enjeu financier majeur pour les assureurs. Un nombre important de r√©clamations inclut des informations falsifi√©es ou exag√©r√©es, ce qui augmente les co√ªts d‚Äôindemnisation et impacte les primes pour l‚Äôensemble des assur√©s.\
Ce projet a pour objectif d‚Äôidentifier les comportements frauduleux √† partir des caract√©ristiques des r√©clamations et des assur√©s, en d√©veloppant des mod√®les de classification capables de pr√©dire si une r√©clamation est frauduleuse ou non.

------------------------------------------------------------------------

## üéØ Objectifs

-   Analyser les variables les plus li√©es au comportement frauduleux
-   Construire des mod√®les d‚Äôapprentissage automatique pour classer les r√©clamations
-   Comparer les performances de plusieurs algorithmes
-   Proposer un outil d‚Äôaide √† la d√©cision permettant de soutenir le processus d‚Äôenqu√™te
-   Traiter le d√©s√©quilibre des classes, caract√©ristique majeure dans ce type de probl√©matique

------------------------------------------------------------------------

## üìä Source des donn√©es

Le projet utilise un jeu de donn√©es public provenant de Kaggle : [Vehicle Claim Fraud Detection Dataset](https://www.kaggle.com/datasets/shivamb/vehicle-claim-fraud-detection){.uri}

Ce dataset contient des informations sur :

-   Les caract√©ristiques du v√©hicule
-   Les d√©tails de la r√©clamation
-   Le profil de l‚Äôassur√©
-   Une variable cible indiquant si la r√©clamation est frauduleuse

------------------------------------------------------------------------

## üõ†Ô∏è M√©thodologie

### üîπ Pr√©paration des donn√©es

-   Nettoyage, transformation et encodage des variables cat√©gorielles
-   D√©tection et traitement des valeurs manquantes
-   Analyse exploratoire des donn√©es (EDA)
-   Gestion du **d√©s√©quilibre des classes** via des techniques comme **SMOTE**

### üîπ Mod√®les test√©s

Plusieurs mod√®les de classification ont √©t√© entra√Æn√©s et compar√©s, notamment :

-   **R√©gression logistique**
-   **Random Forest**
-   **Gradient Boosting (LightGBM, XGBoost)**
-   **k-Nearest Neighbors**
-   **Support Vector Machine**

Les hyperparam√®tres ont √©t√© optimis√©s √† l‚Äôaide de la **validation crois√©e**.

------------------------------------------------------------------------

## üìà √âvaluation des mod√®les

Les mod√®les ont √©t√© √©valu√©s avec des m√©triques adapt√©es aux donn√©es d√©s√©quilibr√©es :

-   **Accuracy**
-   **Pr√©cision**
-   **Rappel**
-   **F1-score**
-   **AUC**

La matrice de confusion a √©t√© utilis√©e pour visualiser les erreurs de classification.

Le meilleur mod√®le a obtenu une **pr√©cision √©lev√©e** tout en maintenant un bon √©quilibre entre d√©tection de la fraude et limitation des faux positifs.

------------------------------------------------------------------------

## üîç R√©sultats principaux

-   Plusieurs variables (ex.: √¢ge du v√©hicule, type de police, historique de r√©clamation) se sont r√©v√©l√©es tr√®s discriminantes
-   Les mod√®les bas√©s sur le **gradient boosting** ont offert les meilleures performances globales
-   Le projet d√©montre que l‚Äôapprentissage automatique peut assister efficacement les √©quipes antifraude

------------------------------------------------------------------------

## üßæ Technologies utilis√©es

-   **Python** : pr√©traitement et mod√©lisation
-   **Scikit-learn / LightGBM / XGBoost**
-   **SMOTE** pour le r√©√©quilibrage des classes
-   **Visualisation** : matplotlib, seaborn
